{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: RNN application -- Tweet Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of original train set: 60000\n",
      "size of original test set: 20000\n",
      "****************************************************************************************************\n",
      "size of train set: 60000, #positive: 30055, #negative: 29945\n",
      "size of test set: 1000, #positive: 510, #negative: 490\n",
      "['it', 'will', 'help', 'relieve', 'your', 'stress', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken']\n",
      "sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "with open(\"./tweets_data/vocabulary.pkl\", \"rb\") as f:\n",
    "    vocabulary = pickle.load(f)\n",
    "\n",
    "# load our data and separate it into tweets and labels\n",
    "train_data = json.load(open('tweets_data/trainTweets_preprocessed.json', 'r'))\n",
    "train_data = list(map(lambda row:(np.array(row[0],dtype=np.int32),str(row[1])),train_data))\n",
    "train_tweets = np.array([t[0] for t in train_data])\n",
    "train_labels = np.array([int(t[1]) for t in train_data])\n",
    "\n",
    "test_data = json.load(open('tweets_data/testTweets_preprocessed.json', 'r'))\n",
    "test_data = list(map(lambda row:(np.array(row[0],dtype=np.int32),str(row[1])),test_data))\n",
    "test_tweets = np.array([t[0] for t in test_data])\n",
    "test_labels = np.array([int(t[1]) for t in test_data])\n",
    "\n",
    "print(\"size of original train set: {}\".format(len(train_tweets)))\n",
    "print(\"size of original test set: {}\".format(len(test_tweets)))\n",
    "\n",
    "# only select first 1000 test sample for test\n",
    "test_tweets = test_tweets[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "print(\"*\"*100)\n",
    "print(\"size of train set: {}, #positive: {}, #negative: {}\".format(len(train_tweets), np.sum(train_labels), len(train_tweets)-np.sum(train_labels)))\n",
    "print(\"size of test set: {}, #positive: {}, #negative: {}\".format(len(test_tweets), np.sum(test_labels), len(test_tweets)-np.sum(test_labels)))\n",
    "\n",
    "# show text of the idx-th train tweet\n",
    "# The 'padtoken' is used to ensure each tweet has the same length\n",
    "idx = 100\n",
    "train_text = [vocabulary[x] for x in train_tweets[idx]]\n",
    "print(train_text)\n",
    "sentiment_label = [\"negative\", \"positive\"]\n",
    "print(\"sentiment: {}\".format(sentiment_label[train_labels[idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: LSTM Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a single-layer lstm network\n",
    "\n",
    "First of all, we'll build a single-layer LSTM network for the analysis. The network structure is the following:\n",
    "\n",
    "![](./img/singleLSTM.png)\n",
    "\n",
    "1. Train the network for 1000 iterations. In each iteration, use batch_size samples to train the network.\n",
    "2. For every 50 iterations, apply the network on the test set, and print out the test accuracy and mean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a linear layer, y = x*w + b\n",
    "def linear(input_, output_size, name, init_bias=0.0):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    with tf.variable_scope(name):\n",
    "        init = tf.truncated_normal([shape[-1], output_size], mean=0.0, stddev=1.0 / shape[-1]**0.5)\n",
    "        W = tf.get_variable(\"weight\", initializer=init)\n",
    "    if init_bias is None:\n",
    "        return tf.matmul(input_, W)\n",
    "    with tf.variable_scope(name):\n",
    "        b = tf.get_variable(\"bias\", [output_size], initializer=tf.constant_initializer(init_bias))\n",
    "    return tf.matmul(input_, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set variables\n",
    "tweet_size = 20\n",
    "hidden_size = 100\n",
    "vocab_size = 7597\n",
    "batch_size = 64\n",
    "\n",
    "# this just makes sure that all our following operations will be placed in the right graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# make placeholders for data we'll feed in\n",
    "tweets = tf.placeholder(tf.int32, [None, tweet_size])\n",
    "labels = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "tweets_onehot = tf.one_hot(tweets, depth=vocab_size, axis=-1)\n",
    "\n",
    "# define the lstm cell\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(hidden_size)\n",
    "\n",
    "# define the op that runs the LSTM, across time, on the data\n",
    "init_state = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, tweets_onehot, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "# define that our final sentiment logit is a linear function of the final state of the LSTM\n",
    "sentiment = linear(final_state[-1], 1, name=\"output\")\n",
    "\n",
    "# define cross entropy/sigmoid loss function\n",
    "sentiment = tf.squeeze(sentiment, [1])\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=sentiment, labels=labels)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# compute accuracy\n",
    "prob = tf.nn.sigmoid(sentiment)\n",
    "prediction = tf.to_float(tf.greater_equal(prob, 0.5))\n",
    "acc = tf.to_float(tf.equal(prediction, labels))\n",
    "acc = tf.reduce_mean(acc)\n",
    "\n",
    "# define optimizer\n",
    "trainer = tf.train.AdamOptimizer()\n",
    "gradients = trainer.compute_gradients(loss)\n",
    "gradients_clipped = [(tf.clip_by_value(t[0],-1,1),t[1]) for t in gradients]\n",
    "optimizer = trainer.apply_gradients(gradients_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  Accuracy =  0.541666666667  Mean Loss =  0.692701220512\n",
      "step:  50  Accuracy =  0.627083333333  Mean Loss =  0.681698779265\n",
      "step:  100  Accuracy =  0.677083333333  Mean Loss =  0.642125983049\n",
      "step:  150  Accuracy =  0.696875  Mean Loss =  0.615378264362\n",
      "step:  200  Accuracy =  0.709375  Mean Loss =  0.59999434435\n",
      "step:  250  Accuracy =  0.719791666667  Mean Loss =  0.589441313449\n",
      "step:  300  Accuracy =  0.725  Mean Loss =  0.582960283142\n",
      "step:  350  Accuracy =  0.702083333333  Mean Loss =  0.575377507682\n",
      "step:  400  Accuracy =  0.7375  Mean Loss =  0.567339816667\n",
      "step:  450  Accuracy =  0.739583333333  Mean Loss =  0.563497719109\n",
      "step:  500  Accuracy =  0.736458333333  Mean Loss =  0.559812697465\n",
      "step:  550  Accuracy =  0.7375  Mean Loss =  0.556642694017\n",
      "step:  600  Accuracy =  0.711458333333  Mean Loss =  0.553126814411\n",
      "step:  650  Accuracy =  0.75  Mean Loss =  0.548556386738\n",
      "step:  700  Accuracy =  0.757291666667  Mean Loss =  0.545825862553\n",
      "step:  750  Accuracy =  0.747916666667  Mean Loss =  0.543397671651\n",
      "step:  800  Accuracy =  0.74375  Mean Loss =  0.541555336575\n",
      "step:  850  Accuracy =  0.748958333333  Mean Loss =  0.538875928357\n",
      "step:  900  Accuracy =  0.747916666667  Mean Loss =  0.536667602308\n"
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "num_steps = train_tweets.shape[0]//batch_size\n",
    "mean_loss = 0\n",
    "train_total = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        start = step*batch_size \n",
    "        end = start + batch_size\n",
    "\n",
    "        batch_tweet = train_tweets[start:end]\n",
    "        batch_label = train_labels[start:end]\n",
    "        # TODO: run the 'optimizer', 'loss', and 'acc' operations in the graph using the batch data\n",
    "        _, train_loss, train_acc = sess.run([optimizer,loss, acc],feed_dict={tweets:batch_tweet,labels:batch_label})\n",
    "        train_total += train_loss\n",
    "        if (step % 50 == 0):\n",
    "            test_batches = test_tweets.shape[0] // batch_size\n",
    "            test_acc = 0\n",
    "            test_loss = 0\n",
    "            for i in range(test_batches):\n",
    "                l = i*batch_size\n",
    "                r = l + batch_size\n",
    "                test_X = test_tweets[l:r]\n",
    "                test_Y = test_labels[l:r]\n",
    "                test_acc += sess.run(acc,feed_dict= {tweets:test_X,labels:test_Y})\n",
    "                test_loss += sess.run(loss,feed_dict= {tweets:test_X,labels:test_Y})\n",
    "                mean_loss = train_total/(step+1)\n",
    "            print(\"step: \",step,\" Accuracy = \",(test_acc/test_batches), \" Mean Loss = \", mean_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a two-layer lstm network\n",
    "\n",
    "Next, we look at a slightly more difficult network structure: a double-layer LSTM. The output of the first LSTM cell is propagated to the second LSTM cell. We only need to make small modifications to the previous network to construct this one.\n",
    "\n",
    "![](./img/doubleLSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR DOUBLE-LAYER LSTM Here\n",
    "tweet_size = 20\n",
    "hidden_size = 100\n",
    "vocab_size = 7597\n",
    "batch_size = 64\n",
    "num_layers = 2\n",
    "\n",
    "# this just makes sure that all our following operations will be placed in the right graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# make placeholders for data we'll feed in\n",
    "tweets = tf.placeholder(tf.int32, [None, tweet_size])\n",
    "labels = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "tweets_onehot = tf.one_hot(tweets, depth=vocab_size, axis=-1)\n",
    "\n",
    "# define the lstm cell\n",
    "# lstm_cell = tf.contrib.rnn.LSTMCell(hidden_size)\n",
    "lstm_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(hidden_size) for i in range(num_layers)])\n",
    "\n",
    "# define the op that runs the LSTM, across time, on the data\n",
    "init_state = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, tweets_onehot, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "# define that our final sentiment logit is a linear function of the final state of the LSTM\n",
    "sentiment = linear(final_state[-1][-1], 1, name=\"output\")\n",
    "\n",
    "# define cross entropy/sigmoid loss function\n",
    "sentiment = tf.squeeze(sentiment, [1])\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=sentiment, labels=labels)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# compute accuracy\n",
    "prob = tf.nn.sigmoid(sentiment)\n",
    "prediction = tf.to_float(tf.greater_equal(prob, 0.5))\n",
    "acc = tf.to_float(tf.equal(prediction, labels))\n",
    "acc = tf.reduce_mean(acc)\n",
    "\n",
    "# define optimizer\n",
    "trainer = tf.train.AdamOptimizer()\n",
    "gradients = trainer.compute_gradients(loss)\n",
    "gradients_clipped = [(tf.clip_by_value(t[0],-1,1),t[1]) for t in gradients]\n",
    "optimizer = trainer.apply_gradients(gradients_clipped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  Accuracy =  0.557291666667  Mean Loss =  0.69356328249\n",
      "step:  50  Accuracy =  0.660416666667  Mean Loss =  0.663909698234\n",
      "step:  100  Accuracy =  0.679166666667  Mean Loss =  0.628872762222\n",
      "step:  150  Accuracy =  0.709375  Mean Loss =  0.604339958816\n",
      "step:  200  Accuracy =  0.717708333333  Mean Loss =  0.590522054268\n",
      "step:  250  Accuracy =  0.740625  Mean Loss =  0.581135162794\n",
      "step:  300  Accuracy =  0.748958333333  Mean Loss =  0.575728826547\n",
      "step:  350  Accuracy =  0.726041666667  Mean Loss =  0.568300984948\n",
      "step:  400  Accuracy =  0.753125  Mean Loss =  0.560448110029\n",
      "step:  450  Accuracy =  0.741666666667  Mean Loss =  0.55604245849\n",
      "step:  500  Accuracy =  0.747916666667  Mean Loss =  0.552745302042\n",
      "step:  550  Accuracy =  0.755208333333  Mean Loss =  0.549964448447\n",
      "step:  600  Accuracy =  0.734375  Mean Loss =  0.54697419279\n",
      "step:  650  Accuracy =  0.757291666667  Mean Loss =  0.542550471063\n",
      "step:  700  Accuracy =  0.766666666667  Mean Loss =  0.539897712338\n",
      "step:  750  Accuracy =  0.759375  Mean Loss =  0.537590816121\n",
      "step:  800  Accuracy =  0.747916666667  Mean Loss =  0.535922896438\n",
      "step:  850  Accuracy =  0.752083333333  Mean Loss =  0.533461405409\n",
      "step:  900  Accuracy =  0.747916666667  Mean Loss =  0.531291635366\n"
     ]
    }
   ],
   "source": [
    "# YOUR TRAINING HERE\n",
    "num_steps = train_tweets.shape[0]//batch_size\n",
    "mean_loss = 0\n",
    "train_total = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        start = step*batch_size\n",
    "        end = start + batch_size\n",
    "                \n",
    "        batch_tweet = train_tweets[start:end]\n",
    "        batch_label = train_labels[start:end]\n",
    "        # TODO: run the 'optimizer', 'loss', and 'acc' operations in the graph using the batch data\n",
    "        _, train_loss, train_acc = sess.run([optimizer,loss, acc],feed_dict={tweets:batch_tweet,labels:batch_label})\n",
    "        train_total += train_loss\n",
    "        if (step % 50 == 0):\n",
    "            test_batches = test_tweets.shape[0] // batch_size\n",
    "            test_acc = 0\n",
    "            for i in range(test_batches):\n",
    "                l = i*batch_size\n",
    "                r = l + batch_size\n",
    "                test_X = test_tweets[l:r]\n",
    "                test_Y = test_labels[l:r]\n",
    "                test_acc += sess.run(acc,feed_dict= {tweets:test_X,labels:test_Y})\n",
    "                test_loss += sess.run(loss,feed_dict= {tweets:test_X,labels:test_Y})\n",
    "                mean_loss = train_total/(step+1)\n",
    "            print(\"step: \",step,\" Accuracy = \",(test_acc/test_batches), \" Mean Loss = \", mean_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Embedding Lookup layer\n",
    "\n",
    "![](./img/embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define an embedding layer\n",
    "\n",
    "It's not hard to imagine in the previous practices, the input we fed in are very sparse because each word was represented as a one-hot vector. This makes it difficult for the network to understand what story the input data is telling. \n",
    "\n",
    "Word embedding: instead of using a one-hot vector to represent each word, we can add an word embedding matrix in which each word is represented as a low-dimensional vector. Note that this representation is not sparse any more, because we're working in a continuous vector space now. Words that share similar/related semantic meaning should be 'close to each other' in this vector space (we could define a distance measure to estimate the closeness). \n",
    "\n",
    "[https://www.tensorflow.org/tutorials/word2vec](https://www.tensorflow.org/tutorials/word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding(input_, vocab_size, output_size, name):\n",
    "    \"\"\"\n",
    "    1. Define an embedding matrix\n",
    "    2. return both the lookup results and the embedding matrix.\n",
    "    \"\"\"\n",
    "    embedding_mat = tf.Variable(tf.random_uniform([vocab_size, output_size], -1.0, 1.0),name = name)\n",
    "    embed_lookup = tf.nn.embedding_lookup(embedding_mat, input_)\n",
    "    return embedding_mat,embed_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a single lstm network with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR EMBEDDING SINGLE-LAYER LSTM HERE\n",
    "tweet_size = 20\n",
    "hidden_size = 100\n",
    "vocab_size = 7597\n",
    "batch_size = 64\n",
    "output_size = 150\n",
    "\n",
    "\n",
    "# this just makes sure that all our following operations will be placed in the right graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# make placeholders for data we'll feed in\n",
    "tweets = tf.placeholder(tf.int32, [None, tweet_size])\n",
    "labels = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "embedding_mat, lookup = embedding(tweets,vocab_size,output_size,'embedding_mat')\n",
    "\n",
    "# define the lstm cell\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(hidden_size)\n",
    "\n",
    "# define the op that runs the LSTM, across time, on the data\n",
    "init_state = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, lookup, initial_state=init_state, dtype=tf.float32)\n",
    "\n",
    "# define that our final sentiment logit is a linear function of the final state of the LSTM\n",
    "sentiment = linear(final_state[-1], 1, name=\"output\")\n",
    "\n",
    "# define cross entropy/sigmoid loss function\n",
    "sentiment = tf.squeeze(sentiment, [1])\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=sentiment, labels=labels)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# compute accuracy\n",
    "prob = tf.nn.sigmoid(sentiment)\n",
    "prediction = tf.to_float(tf.greater_equal(prob, 0.5))\n",
    "acc = tf.to_float(tf.equal(prediction, labels))\n",
    "acc = tf.reduce_mean(acc)\n",
    "\n",
    "# define optimizer\n",
    "trainer = tf.train.AdamOptimizer()\n",
    "gradients = trainer.compute_gradients(loss)\n",
    "gradients_clipped = [(tf.clip_by_value(t[0],-1,1),t[1]) for t in gradients]\n",
    "optimizer = trainer.apply_gradients(gradients_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  Accuracy =  0.534375  Mean Loss =  0.698773264885\n",
      "step:  50  Accuracy =  0.553125  Mean Loss =  0.693176641184\n",
      "step:  100  Accuracy =  0.584375  Mean Loss =  0.688724697816\n",
      "step:  150  Accuracy =  0.641666666667  Mean Loss =  0.674904002654\n",
      "step:  200  Accuracy =  0.675  Mean Loss =  0.659717993357\n",
      "step:  250  Accuracy =  0.708333333333  Mean Loss =  0.645617225731\n",
      "step:  300  Accuracy =  0.708333333333  Mean Loss =  0.639122467401\n",
      "step:  350  Accuracy =  0.698958333333  Mean Loss =  0.628749201355\n",
      "step:  400  Accuracy =  0.698958333333  Mean Loss =  0.619741013\n",
      "step:  450  Accuracy =  0.723958333333  Mean Loss =  0.612193536534\n",
      "step:  500  Accuracy =  0.730208333333  Mean Loss =  0.606019022282\n",
      "step:  550  Accuracy =  0.751041666667  Mean Loss =  0.600268600857\n",
      "step:  600  Accuracy =  0.75  Mean Loss =  0.594674198679\n",
      "step:  650  Accuracy =  0.75  Mean Loss =  0.588545608401\n",
      "step:  700  Accuracy =  0.752083333333  Mean Loss =  0.583799130821\n",
      "step:  750  Accuracy =  0.740625  Mean Loss =  0.579306631526\n",
      "step:  800  Accuracy =  0.741666666667  Mean Loss =  0.575870769636\n",
      "step:  850  Accuracy =  0.745833333333  Mean Loss =  0.571495951098\n",
      "step:  900  Accuracy =  0.754166666667  Mean Loss =  0.567849947596\n"
     ]
    }
   ],
   "source": [
    "# YOUR TRAINING HERE\n",
    "num_steps = train_tweets.shape[0] // batch_size\n",
    "mean_loss = 0\n",
    "train_total = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        start_idx = step*batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "\n",
    "        batchX = train_tweets[start_idx:end_idx]\n",
    "        batchY = train_labels[start_idx:end_idx]\n",
    "        # TODO: run the 'optimizer', 'loss', and 'acc' operations in the graph using the batch data\n",
    "        _, train_loss, train_acc = sess.run([optimizer,loss, acc],feed_dict= \\\n",
    "                                                {tweets:batchX,labels:batchY})\n",
    "        train_total += train_loss\n",
    "        if (step % 50 == 0):\n",
    "            test_batches = test_tweets.shape[0] // batch_size\n",
    "            test_acc = 0\n",
    "            for i in range(test_batches):\n",
    "                idx1 = i*batch_size\n",
    "                idx2 = idx1 + batch_size\n",
    "                test_X = test_tweets[idx1:idx2]\n",
    "                test_Y = test_labels[idx1:idx2]\n",
    "                test_acc += sess.run(acc,feed_dict= {tweets:test_X,labels:test_Y})\n",
    "                \n",
    "            mean_loss = train_total/(step+1)\n",
    "            print(\"step: \",step,\" Accuracy = \",(test_acc/test_batches), \" Mean Loss = \", mean_loss)\n",
    "            # TODO: get test accuracy and loss, and print them out.\n",
    "    vocab_embeddings = sess.run(embedding_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize word vectors via tSNE\n",
    "\n",
    "First, you need to retrieve **embedding matrix** from the network. Then use tSNE to reduce each low-dimensional word vector into a 2D vector. \n",
    "\n",
    "And then, you should visualize some interesting word pairs in 2D panel. You may find **scatter** function in **matplotlib.pyplot** useful.\n",
    "\n",
    "\n",
    "You can use **TSNE** tool provided in **scikit-learn**.\n",
    "\n",
    "The result for female-male pairs should look like, and you will observe that king-men and queen-women are parallel to each other in a 2D panel.\n",
    "\n",
    "\n",
    "![](./img/tsne_female_male.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7597, 150)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_male = [\"men\", \"women\", \"king\", \"queen\"]\n",
    "country_capital = [\"spain\", \"madrid\", \"italy\", \"rome\", \"japan\", \"tokyo\"]\n",
    "#fruit_clour = [\"apple\", \"red\", \"lemon\", \"yellow\", \"mandarin\", \"orange\"]\n",
    "\n",
    "vocab_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7597, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "### your code here\n",
    "X_embedded = TSNE( n_components=2, init='pca', n_iter=1000, random_state=10).fit_transform(vocab_embeddings)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUiFDQpJUyJCQJBX6/7M4Cz8z8c15AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c54a67b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def wordvec(vocab,words):\n",
    "    idx = [np.where(vocab==a) for a in words]\n",
    "    res = []\n",
    "    for i in range(len(idx)):\n",
    "        res.append(idx[i][0][0])\n",
    "    return res\n",
    "X = X_embedded[wordvec(vocabulary,female_male)]\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "\n",
    "for i, txt in enumerate(female_male):\n",
    "    plt.annotate(txt, (X[i,0],X[i,1]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c54a6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X_embedded[wordvec(vocabulary,country_capital)]\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "\n",
    "for i, txt in enumerate(country_capital):\n",
    "    plt.annotate(txt, (X[i,0],X[i,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your observation of these word vectors\n",
    "\n",
    "Answer: **We see in the above two example that the vectors joining men-king and women-queen seem to be parallel as expected based on theory. This however is also true in the second case. The vectors joining japan-rome and madrid-spain are almost parallel and italy-rome is randomly oriented **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
